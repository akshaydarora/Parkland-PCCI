{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 : Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import  Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from statistics import mode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_curve,auc,confusion_matrix,accuracy_score,classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from operator import itemgetter\n",
    "#Advanced optimization\n",
    "from scipy import optimize as op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the clean data : Numeric and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('categ_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df=pd.read_pickle('numeric_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>newPurpose</th>\n",
       "      <th>verification</th>\n",
       "      <th>defaulter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>RENT</td>\n",
       "      <td>GA</td>\n",
       "      <td>car</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>AIR RESOURCES BOARD</td>\n",
       "      <td>RENT</td>\n",
       "      <td>CA</td>\n",
       "      <td>other</td>\n",
       "      <td>Verified</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>University Medical Group</td>\n",
       "      <td>RENT</td>\n",
       "      <td>OR</td>\n",
       "      <td>other</td>\n",
       "      <td>Verified</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>Veolia Transportaton</td>\n",
       "      <td>RENT</td>\n",
       "      <td>AZ</td>\n",
       "      <td>personal</td>\n",
       "      <td>Verified</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>Southern Star Photography</td>\n",
       "      <td>RENT</td>\n",
       "      <td>NC</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grade sub_grade                  emp_title home_ownership addr_state  \\\n",
       "0     C        C4                      Ryder           RENT         GA   \n",
       "1     C        C1        AIR RESOURCES BOARD           RENT         CA   \n",
       "2     B        B5   University Medical Group           RENT         OR   \n",
       "3     A        A4       Veolia Transportaton           RENT         AZ   \n",
       "4     C        C5  Southern Star Photography           RENT         NC   \n",
       "\n",
       "    newPurpose  verification defaulter  \n",
       "0          car      Verified       Yes  \n",
       "1        other      Verified        No  \n",
       "2        other      Verified        No  \n",
       "3     personal      Verified        No  \n",
       "4  credit_card  Not Verified        No  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership</th>\n",
       "      <td>RENT</td>\n",
       "      <td>RENT</td>\n",
       "      <td>RENT</td>\n",
       "      <td>RENT</td>\n",
       "      <td>RENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state</th>\n",
       "      <td>GA</td>\n",
       "      <td>CA</td>\n",
       "      <td>OR</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newPurpose</th>\n",
       "      <td>car</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>personal</td>\n",
       "      <td>credit_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification</th>\n",
       "      <td>Verified</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Not Verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defaulter</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1         2         3             4\n",
       "grade                  C         C         B         A             C\n",
       "home_ownership      RENT      RENT      RENT      RENT          RENT\n",
       "addr_state            GA        CA        OR        AZ            NC\n",
       "newPurpose           car     other     other  personal   credit_card\n",
       "verification    Verified  Verified  Verified  Verified  Not Verified\n",
       "defaulter            Yes        No        No        No            No"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=df.copy()\n",
    "predictors.drop(['defaulter'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['emp_title','sub_grade'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for NaNs in check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanSummary(dataset):\n",
    "    summary={}\n",
    "    \n",
    "    nanS=dataset.isnull().sum().sort_values(ascending=False)\n",
    "    for key in nanS.keys():\n",
    "        if nanS[key] > 0:\n",
    "            summary[key]=nanS[key]\n",
    "    if summary == {}:\n",
    "        summary='Data is now Clean'\n",
    "    \n",
    "    return summary        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Dummy Categorical Variables using : One-Hot- Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=pd.get_dummies(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred=pd.concat([num_df,dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data is now Clean'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanSummary(X_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Response Labels : '0' : Non Defaulter , '1' : Yes Defaulter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "df[\"y\"] = lb.fit_transform(df[\"defaulter\"])\n",
    "df[[\"defaulter\", \"y\"]].head(10)\n",
    "response=df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([X_pred,response],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data is now Clean'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanSummary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It can be seen from above that this dataset suffers from a severe class imbalance problem and it this problem is not resolved then it can lead to falsified predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    33969\n",
       "1     5883\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=df['y'].value_counts()\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To solve this class imbalance problem the strategy used in this algorithm is 'Down Sampling the Majority Class' . \n",
    "\n",
    "### In this strategy , we take the following steps:\n",
    "\n",
    "#### First, we'll separate observations from each class into different DataFrames.\n",
    "#### Next, we'll resample the majority class without replacement, setting the number of samples to match that of the minority class.\n",
    "#### Finally, we'll combine the down-sampled majority class DataFrame with the original minority class DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntClass0= count[0]\n",
    "cntClass1= count[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = df[df.y==0]\n",
    "df_minority = df[df.y==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=cntClass1,     # to match minority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5883\n",
       "0    5883\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data is now Clean'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nanSummary(df_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_downsampled.drop('y',axis=1)\n",
    "y = df_downsampled['y']\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning of a Random Forest \n",
    "\n",
    "### Grid Search Method is used for searching optimal hyperparameters\n",
    "\n",
    "### We initially start with arbitrary parameters and search for best parameters by assigning top scoring parameters to the model. Thus we rank the model by its accuracy and select these parameters for our final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParamSummary(grid_scores, n_top):\n",
    "    BestScores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(BestScores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.4f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmodel = RandomForestClassifier(min_samples_split = 3, \n",
    "                             max_leaf_nodes = 75, \n",
    "                             n_estimators = 100,\n",
    "                             max_depth = 6,\n",
    "                             min_samples_leaf = 5,\n",
    "                             oob_score =True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='auto', max_leaf_nodes=75,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RFmodel.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916312659303\n"
     ]
    }
   ],
   "source": [
    "print( accuracy_score(y_validation, pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print( np.unique( pred ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1054   90]\n",
      " [ 107 1103]]\n"
     ]
    }
   ],
   "source": [
    " print(confusion_matrix(y_validation, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the Metrics : Recall, Precision and f1 score for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.92      0.91      1144\n",
      "          1       0.92      0.91      0.92      1210\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validation,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91644945963127789"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_validation, pred, pos_label=1)\n",
    "auc(fpr, tpr)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Approach (Synthetic Minority oversampling approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "import imblearn\n",
    "from imblearn import over_sampling\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(ratio='auto', random_state=40, k_neighbors=5,\n",
    "           m=None, m_neighbors=10, out_step=0.5, \n",
    "           kind='regular', n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=df.drop(['y'],axis=1)\n",
    "y_data=df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27896, 91)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res_df=pd.DataFrame(y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23805\n",
       "0    23805\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res_df[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning of a Random Forest \n",
    "\n",
    "### Grid Search Method is used for searching optimal hyperparameters\n",
    "\n",
    "### We initially start with arbitrary parameters and search for best parameters by assigning top scoring parameters to the model. Thus we rank the model by its accuracy and select these parameters for our final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(random_state = 84)\n",
    "\n",
    "param_grid = {\"n_estimators\": [100, 200],\n",
    "              \"max_depth\": [5, 6],\n",
    "              \"min_samples_split\": [5, 10],\n",
    "              \"min_samples_leaf\": [3, 5],\n",
    "              \"max_leaf_nodes\": [50, 75]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.9591)\n",
      "Parameters: {'min_samples_leaf': 3, 'n_estimators': 200, 'max_leaf_nodes': 75, 'min_samples_split': 10, 'max_depth': 6}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.9590)\n",
      "Parameters: {'min_samples_leaf': 5, 'n_estimators': 200, 'max_leaf_nodes': 75, 'min_samples_split': 5, 'max_depth': 6}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.9590)\n",
      "Parameters: {'min_samples_leaf': 5, 'n_estimators': 200, 'max_leaf_nodes': 75, 'min_samples_split': 10, 'max_depth': 6}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.9590)\n",
      "Parameters: {'min_samples_leaf': 3, 'n_estimators': 200, 'max_leaf_nodes': 75, 'min_samples_split': 5, 'max_depth': 6}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(RF_model, param_grid=param_grid)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "hyperParamSummary(grid_search.grid_scores_, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Hyperparameters from Summary for our Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmodel = RandomForestClassifier(min_samples_split = 3, \n",
    "                             max_leaf_nodes = 75, \n",
    "                             n_estimators = 200,\n",
    "                             max_depth = 6,\n",
    "                             min_samples_leaf = 10,\n",
    "                             oob_score =True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='auto', max_leaf_nodes=75,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFmodel.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RFmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953830712613\n"
     ]
    }
   ],
   "source": [
    "print( accuracy_score(y_test, pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print( np.unique( pred ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9975  189]\n",
      " [ 363 1429]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the Metrics : Recall, Precision and f1 score for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97     10164\n",
      "          1       0.88      0.80      0.84      1792\n",
      "\n",
      "avg / total       0.95      0.95      0.95     11956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
